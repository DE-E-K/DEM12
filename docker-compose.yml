version: "3.9"

x-airflow-common: &airflow-common
  image: apache/airflow:2.9.1
  env_file: .env
  environment:
    AIRFLOW__CORE__EXECUTOR: LocalExecutor
    AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: ${AIRFLOW__DATABASE__SQL_ALCHEMY_CONN}
    AIRFLOW__CORE__FERNET_KEY: ${AIRFLOW__CORE__FERNET_KEY}
    AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: ${AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION}
    AIRFLOW__CORE__LOAD_EXAMPLES: ${AIRFLOW__CORE__LOAD_EXAMPLES}
    AIRFLOW__WEBSERVER__SECRET_KEY: ${AIRFLOW__WEBSERVER__SECRET_KEY}
    # Pass MinIO / Postgres settings so DAGs can read from include/config.py
    POSTGRES_HOST: ${POSTGRES_HOST}
    POSTGRES_PORT: ${POSTGRES_PORT}
    POSTGRES_DB: ${POSTGRES_DB}
    POSTGRES_USER: ${POSTGRES_USER}
    POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
    MINIO_ROOT_USER: ${MINIO_ROOT_USER}
    MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD}
    MINIO_ENDPOINT: ${MINIO_ENDPOINT}
    MINIO_RAW_BUCKET: ${MINIO_RAW_BUCKET}
    MINIO_PROCESSED_BUCKET: ${MINIO_PROCESSED_BUCKET}
  volumes:
    - ./dags:/opt/airflow/dags
    - ./include:/opt/airflow/include
    - airflow_logs:/opt/airflow/logs
  depends_on:
    postgres:
      condition: service_healthy
  restart: unless-stopped

services:
  # ── PostgreSQL ────────────────────────────────────────────
  postgres:
    image: postgres:16-alpine
    container_name: platform_postgres
    env_file: .env
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init-scripts:/docker-entrypoint-initdb.d
    ports:
      - "5432:5432"
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}" ]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  # ── MinIO ─────────────────────────────────────────────────
  minio:
    image: minio/minio:latest
    container_name: platform_minio
    env_file: .env
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD}
    command: server /data --console-address ":9001"
    volumes:
      - minio_data:/data
    ports:
      - "9000:9000" # S3 API
      - "9001:9001" # Web Console
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:9000/minio/health/live" ]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  # ── MinIO Bucket Init (runs once, then exits) ─────────────
  minio-init:
    image: minio/mc:latest
    container_name: platform_minio_init
    env_file: .env
    depends_on:
      minio:
        condition: service_healthy
    entrypoint: /bin/sh /init/create_buckets.sh
    volumes:
      - ./minio-init:/init
    restart: "no"

  # ── Airflow Init (DB migrate + admin user) ─────────────────
  airflow-init:
    <<: *airflow-common
    container_name: platform_airflow_init
    entrypoint: /bin/bash
    command:
      - -c
      - |
        airflow db migrate
        airflow users create \
          --username ${AIRFLOW_ADMIN_USERNAME} \
          --firstname Admin \
          --lastname User \
          --role Admin \
          --email ${AIRFLOW_ADMIN_EMAIL} \
          --password ${AIRFLOW_ADMIN_PASSWORD} || true
    restart: "no"

  # ── Airflow Webserver ──────────────────────────────────────
  airflow-webserver:
    <<: *airflow-common
    container_name: platform_airflow_webserver
    command: webserver
    ports:
      - "8080:8080"
    healthcheck:
      test: [ "CMD", "curl", "--fail", "http://localhost:8080/health" ]
      interval: 30s
      timeout: 10s
      retries: 5
    depends_on:
      airflow-init:
        condition: service_completed_successfully
      postgres:
        condition: service_healthy

  # ── Airflow Scheduler ──────────────────────────────────────
  airflow-scheduler:
    <<: *airflow-common
    container_name: platform_airflow_scheduler
    command: scheduler
    healthcheck:
      test: [ "CMD-SHELL", "airflow jobs check --job-type SchedulerJob --hostname \"$${HOSTNAME}\"" ]
      interval: 30s
      timeout: 10s
      retries: 5
    depends_on:
      airflow-init:
        condition: service_completed_successfully
      postgres:
        condition: service_healthy

  # ── Metabase ───────────────────────────────────────────────
  metabase:
    image: metabase/metabase:latest
    container_name: platform_metabase
    env_file: .env
    environment:
      MB_DB_TYPE: ${MB_DB_TYPE}
      MB_DB_DBNAME: ${MB_DB_DBNAME}
      MB_DB_PORT: ${MB_DB_PORT}
      MB_DB_USER: ${MB_DB_USER}
      MB_DB_PASS: ${MB_DB_PASS}
      MB_DB_HOST: ${MB_DB_HOST}
    ports:
      - "3000:3000"
    healthcheck:
      test: [ "CMD", "curl", "--fail", "http://localhost:3000/api/health" ]
      interval: 30s
      timeout: 10s
      retries: 10
    depends_on:
      postgres:
        condition: service_healthy
    restart: unless-stopped

  # ── Data Generator (run on-demand) ────────────────────────
  data-generator:
    build:
      context: ./data-generator
      dockerfile: Dockerfile
    container_name: platform_data_generator
    env_file: .env
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD}
      MINIO_ENDPOINT: ${MINIO_ENDPOINT}
      MINIO_RAW_BUCKET: ${MINIO_RAW_BUCKET}
      GENERATOR_NUM_ROWS: ${GENERATOR_NUM_ROWS}
      GENERATOR_SEED: ${GENERATOR_SEED}
    depends_on:
      minio:
        condition: service_healthy
      minio-init:
        condition: service_completed_successfully
    profiles:
      - tools # run with: docker compose --profile tools run --rm data-generator

volumes:
  postgres_data:
  minio_data:
  airflow_logs:
  metabase_data:


networks:
  default:
    name: platform_network
